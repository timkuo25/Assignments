{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1.1\n",
    "    - \">50K\"編為1，反之編為0、刪除具有空值的資料、進行1 of k encoding, 資料中沒出現十筆以上的discrete value不編入feature\n",
    "    - Armed-Forces和Holand-Netherlands沒被編入features\n",
    "    - 共有30162筆training data、15060筆testing data、102個features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "load = np.loadtxt(\"C:\\\\Users\\\\tim_ezemnng\\\\Desktop\\\\train.csv\" ,dtype = np.single, delimiter=\",\")\n",
    "load2 = np.loadtxt(\"C:\\\\Users\\\\tim_ezemnng\\\\Desktop\\\\test.csv\" ,dtype = np.single, delimiter=\",\")\n",
    "\n",
    "arr = np.array(load)\n",
    "arr2 = np.array(load2)\n",
    "\n",
    "con_list = [0, 8, 25, 59, 60, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = arr[0:, 0: 102]\n",
    "y_train = arr[0:, 102]\n",
    "x_test = arr2[0:, 0: 102]\n",
    "y_test = arr2[0:, 102]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1.2\n",
    "    - Let $z_1 = t_n\\ln{y_n}, \\ z_2 = (1 - t_n)\\ln(1 - y_n)$\n",
    "    - Let $z = z_1 + z_2$\n",
    "    - Let $z_3 = \\frac{1}{2} w^T \\Lambda w = \\frac{1}{2}(w_1^2\\lambda_1 + w_2^2\\lambda_2 + ... + w_n^2\\lambda_n)$\n",
    "    - $\\frac{\\partial z_3}{\\partial w} = \\Lambda w$\n",
    "    - According to the derivation in the lecture, $\\frac{\\partial z}{\\partial w} = (t_n - y_n)x_n$\n",
    "    - Therefore, $\\nabla E = \\Lambda w +\\sum\\limits_{n = 1}^N(y_n - t_n)x_n = \\Lambda w + x^T(y - t)$\n",
    "    - $H = \\nabla \\nabla E = \\Lambda + x^TRx$ , where $R$ is a diagnal matrix with elements $R_{nn} = y_n (1 - y_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1.3\n",
    "    - 建立mylogistic_l2的class, 其中有member function fit(), predict()\n",
    "    - 以Linear Regression的封閉解為起始w, 計算出新的w, 一直迭代至improvement小於tol或次數超過max_iter\n",
    "    - 顯示出學習到的w與預測準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2:\n",
    "    reg_vec = np.array([])\n",
    "    max_iter = 0\n",
    "    tol = 0\n",
    "    add_intercept = True\n",
    "    w_old = np.array([])\n",
    "    w_new = np.array([])\n",
    "    \n",
    "    Lambda = np.array([])   \n",
    "    identity = np.array([])   \n",
    "\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "        self.Lambda = np.eye(103)\n",
    "        self.identity = np.eye(103)\n",
    "\n",
    "        for i in range(0, 103):\n",
    "            self.Lambda[i][i] = reg_vec[i]\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        x = X_train\n",
    "        t = Y_train\n",
    "        t = np.reshape(t, (len(t), 1))\n",
    "        x = np.c_[ x, np.ones(len(X_train)) ]\n",
    "        y = np.zeros(len(x))\n",
    "        y = np.reshape(y, (len(y), 1))\n",
    "        b = np.mean(self.reg_vec)\n",
    "        stop = False\n",
    "\n",
    "        #w_old\n",
    "        self.w_old = x.T.dot(x) + (b * self.identity) # x^Tx + bI\n",
    "        self.w_old = np.linalg.inv(self.w_old).dot(x.T).dot(t) # (x^Tx + bI)^-1x^Tt\n",
    "\n",
    "            \n",
    "        for i in range(0, self.max_iter):\n",
    "            \n",
    "            for j in range(len(x)):\n",
    "                y[j][0] = 1  / (1 + np.exp(-self.w_old.T.dot(x[j])))\n",
    "            # E\n",
    "            sum_arr = np.zeros(len(y))\n",
    "            for j in range(len(y)):\n",
    "                sum_arr[j] = t[j][0] * np.log(y[j][0]) + (1 - t[j][0]) * np.log((1 - y[j][0]))\n",
    "                \n",
    "            cur_E = 0.5 * self.w_old.T.dot(self.Lambda).dot(self.w_old) - np.sum(sum_arr)\n",
    "            #print(\"i = \", i)\n",
    "            #print(cur_E)\n",
    "            \n",
    "            #gradient\n",
    "            grad = self.Lambda.dot(self.w_old) + x.T.dot(y - t)\n",
    "        \n",
    "            # hessian\n",
    "            tmp = np.reshape(x[0], (len(x[0]), 1))\n",
    "            H = y[0][0] * (1 - y[0][0]) * tmp.dot(tmp.T)\n",
    "            \n",
    "            for j in range(1, len(x)):\n",
    "                tmp = np.reshape(x[j], (len(x[j]), 1))\n",
    "                H = H + (y[j][0] * (1 - y[j][0]) * tmp.dot(tmp.T))\n",
    "            H = H + self.Lambda\n",
    "            \n",
    "            #w_new\n",
    "            H_i = np.linalg.inv(H)\n",
    "            self.w_new = self.w_old - H_i.dot(grad)\n",
    "            \n",
    "            for j in range(len(x)):\n",
    "                y[j][0] = 1  / (1 + np.exp(-self.w_new.T.dot(x[j])))\n",
    "\n",
    "            # E\n",
    "            sum_arr = np.zeros(len(y))\n",
    "            for j in range(0, len(y)):\n",
    "                sum_arr[j] = t[j][0] * np.log(y[j][0]) + (1 - t[j][0]) * np.log((1 - y[j][0]))\n",
    "            E = 0.5 * self.w_new.T.dot(self.Lambda).dot(self.w_new) - np.sum(sum_arr)\n",
    "            \n",
    "            if (np.abs(cur_E - E) <= self.tol):\n",
    "                stop = True\n",
    "                \n",
    "            self.w_old = self.w_new\n",
    "            \n",
    "            if stop:\n",
    "                return\n",
    "            \n",
    "    def predict(self, x):\n",
    "        x_te = x\n",
    "        x_te = np.c_[ x_te, np.ones(len(x))]\n",
    "        y = np.zeros(len(x_te))\n",
    "        \n",
    "        for i in range(0, len(x_te)):\n",
    "            y_n = 1  / (1 + np.exp(-self.w_new.T.dot(x_te[i])))\n",
    "            if y_n > 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "        return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Case 1: 所有$\\lambda$都設為1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned w = \n",
      "[[ 2.48591297e-02]\n",
      " [-3.10975202e-01]\n",
      " [-7.94111556e-01]\n",
      " [-1.29181491e-01]\n",
      " [ 1.89694411e-01]\n",
      " [-4.97719501e-01]\n",
      " [-6.18745003e-01]\n",
      " [-1.17270706e+00]\n",
      " [ 7.26281835e-07]\n",
      " [ 1.28534378e-01]\n",
      " [-1.00989638e-01]\n",
      " [-5.44907403e-01]\n",
      " [-2.50481306e-01]\n",
      " [ 6.82097029e-01]\n",
      " [-3.08326937e-01]\n",
      " [-1.27584811e-01]\n",
      " [-4.96565839e-01]\n",
      " [-6.29791388e-01]\n",
      " [-3.82721832e-01]\n",
      " [ 2.99991415e-01]\n",
      " [-9.99810289e-02]\n",
      " [-4.52249247e-01]\n",
      " [ 5.87953355e-01]\n",
      " [-2.62922225e-01]\n",
      " [-1.37579993e+00]\n",
      " [ 1.85806163e-01]\n",
      " [ 8.38966933e-01]\n",
      " [-1.00975740e+00]\n",
      " [-1.50523218e+00]\n",
      " [-1.08232391e+00]\n",
      " [-8.14848363e-01]\n",
      " [-9.56673066e-01]\n",
      " [ 1.19612258e+00]\n",
      " [ 5.68478621e-01]\n",
      " [-2.46913576e-02]\n",
      " [-9.03671285e-01]\n",
      " [ 2.05962313e-01]\n",
      " [ 7.15174653e-01]\n",
      " [ 4.29670534e-01]\n",
      " [-7.73348089e-01]\n",
      " [-3.53722827e-01]\n",
      " [-8.78492150e-02]\n",
      " [-1.06504054e+00]\n",
      " [-1.78947443e-01]\n",
      " [-1.69395623e+00]\n",
      " [ 4.99488476e-01]\n",
      " [ 7.47819835e-01]\n",
      " [-1.50192087e+00]\n",
      " [-5.76254828e-01]\n",
      " [-3.75781253e-01]\n",
      " [-1.12608337e+00]\n",
      " [-5.01524915e-01]\n",
      " [-4.84594618e-01]\n",
      " [-2.92668732e-01]\n",
      " [-1.02439618e+00]\n",
      " [-8.96890177e-01]\n",
      " [-6.35195701e-01]\n",
      " [-1.24007039e+00]\n",
      " [-2.09367501e+00]\n",
      " [ 3.16590245e-04]\n",
      " [ 6.38679434e-04]\n",
      " [ 2.90215841e-02]\n",
      " [ 2.89337136e-01]\n",
      " [ 9.03420736e-01]\n",
      " [ 3.77034140e-01]\n",
      " [-1.81402777e-01]\n",
      " [ 4.04668560e-01]\n",
      " [ 5.23589384e-01]\n",
      " [-6.90804284e-01]\n",
      " [-3.44708811e-01]\n",
      " [ 2.92357805e-01]\n",
      " [-6.70323916e-01]\n",
      " [-9.81576059e-01]\n",
      " [-5.46920552e-01]\n",
      " [ 4.27865170e-01]\n",
      " [ 1.03362979e-01]\n",
      " [-1.63971889e-01]\n",
      " [ 3.91129903e-01]\n",
      " [ 8.22875669e-01]\n",
      " [ 8.03243762e-02]\n",
      " [ 9.41389495e-02]\n",
      " [-8.34197419e-01]\n",
      " [-4.39859204e-01]\n",
      " [ 7.97357705e-02]\n",
      " [ 4.50497096e-01]\n",
      " [ 5.45751678e-01]\n",
      " [-9.47705967e-01]\n",
      " [-3.50891475e-01]\n",
      " [-1.07395557e-01]\n",
      " [-7.79910247e-02]\n",
      " [ 4.53277949e-02]\n",
      " [-1.31374667e+00]\n",
      " [-4.02281380e-03]\n",
      " [-1.09516216e-01]\n",
      " [-4.07586321e-01]\n",
      " [-9.03628229e-02]\n",
      " [-3.31100773e-01]\n",
      " [ 5.39068128e-01]\n",
      " [-4.09492097e-01]\n",
      " [-1.88816101e-01]\n",
      " [-4.47783816e-01]\n",
      " [-4.71983494e-02]\n",
      " [-3.33374540e+00]]\n",
      "accuracy =  0.8480743691899071\n"
     ]
    }
   ],
   "source": [
    "lambda_vec1 = np.zeros(103)\n",
    "\n",
    "for i in range(0, 103):\n",
    "    lambda_vec1[i] = 1\n",
    "    \n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "y_pred1 = logic1.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, len(y_pred1)):\n",
    "    if (y_test[i] == y_pred1[i]):\n",
    "        count += 1\n",
    "\n",
    "print(\"learned w = \")        \n",
    "print(logic1.w_new)\n",
    "print(\"accuracy = \", count / len(y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Case 2: 所有$\\lambda$都設為1, 除了截距項設為0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned w = \n",
      "[[ 2.54336822e-02]\n",
      " [ 2.09126595e-01]\n",
      " [-2.79821710e-01]\n",
      " [ 3.82731145e-01]\n",
      " [ 7.05717318e-01]\n",
      " [ 1.78026502e-02]\n",
      " [-1.04552949e-01]\n",
      " [-9.31003049e-01]\n",
      " [ 7.50706804e-07]\n",
      " [-7.43801938e-02]\n",
      " [ 2.18010722e-02]\n",
      " [-1.06210390e-01]\n",
      " [-1.95742295e-02]\n",
      " [ 2.67049827e-01]\n",
      " [-4.01951495e-01]\n",
      " [-1.13370201e-01]\n",
      " [ 1.37527872e-01]\n",
      " [ 1.16361326e-01]\n",
      " [-5.68864876e-02]\n",
      " [-1.15929725e-02]\n",
      " [ 7.06129017e-01]\n",
      " [ 9.08118759e-02]\n",
      " [ 6.79669927e-02]\n",
      " [ 5.36014978e-01]\n",
      " [-1.15969699e+00]\n",
      " [ 2.95324923e-01]\n",
      " [ 1.36750998e+00]\n",
      " [-5.26538170e-01]\n",
      " [-1.01532721e+00]\n",
      " [-6.05766406e-01]\n",
      " [-3.41948994e-01]\n",
      " [-4.92456773e-01]\n",
      " [ 1.61452756e+00]\n",
      " [ 8.18714334e-01]\n",
      " [ 2.28422252e-01]\n",
      " [-6.49283758e-01]\n",
      " [ 4.55411798e-01]\n",
      " [ 9.64856017e-01]\n",
      " [ 6.78427763e-01]\n",
      " [-5.20782272e-01]\n",
      " [-9.91243553e-02]\n",
      " [ 1.64109182e-01]\n",
      " [-8.17967488e-01]\n",
      " [ 7.31938650e-02]\n",
      " [-1.55300394e+00]\n",
      " [ 7.51030496e-01]\n",
      " [ 1.28789619e+00]\n",
      " [-9.36996676e-01]\n",
      " [-4.21151177e-02]\n",
      " [ 1.99456835e-01]\n",
      " [-5.83542676e-01]\n",
      " [ 7.53014460e-02]\n",
      " [ 1.95854174e-01]\n",
      " [ 3.94360616e-01]\n",
      " [-3.72048376e-01]\n",
      " [-2.61235809e-01]\n",
      " [ 4.30693947e-02]\n",
      " [ 4.27150728e-01]\n",
      " [-4.27150728e-01]\n",
      " [ 3.17024478e-04]\n",
      " [ 6.39652126e-04]\n",
      " [ 2.94914512e-02]\n",
      " [ 3.96789072e-01]\n",
      " [ 1.00965472e+00]\n",
      " [ 4.72832596e-01]\n",
      " [-7.36414561e-02]\n",
      " [ 5.02337197e-01]\n",
      " [ 6.23911101e-01]\n",
      " [-6.50777756e-01]\n",
      " [-2.48769642e-01]\n",
      " [ 3.79606530e-01]\n",
      " [-5.88433187e-01]\n",
      " [-8.98503738e-01]\n",
      " [-4.58396920e-01]\n",
      " [ 5.27833699e-01]\n",
      " [ 1.94794455e-01]\n",
      " [-1.43574429e-01]\n",
      " [ 4.89030076e-01]\n",
      " [ 9.31972681e-01]\n",
      " [ 1.76281854e-01]\n",
      " [ 1.87606692e-01]\n",
      " [-7.54273374e-01]\n",
      " [-3.10421302e-01]\n",
      " [ 1.74545517e-01]\n",
      " [ 5.25952046e-01]\n",
      " [ 6.28755385e-01]\n",
      " [-8.67620758e-01]\n",
      " [-2.87259337e-01]\n",
      " [-2.75702542e-02]\n",
      " [ 6.72286166e-03]\n",
      " [ 1.24844059e-01]\n",
      " [-1.24053337e+00]\n",
      " [ 6.14826821e-02]\n",
      " [-2.96923356e-02]\n",
      " [-3.32413818e-01]\n",
      " [-3.10934765e-02]\n",
      " [-2.72168680e-01]\n",
      " [ 6.10526925e-01]\n",
      " [-3.15345727e-01]\n",
      " [-1.23870297e-01]\n",
      " [-3.81261235e-01]\n",
      " [ 2.48070503e-02]\n",
      " [-8.88722778e+00]]\n",
      "accuracy =  0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "lambda_vec2 = np.zeros(103)\n",
    "\n",
    "for i in range(0, 103):\n",
    "    lambda_vec2[i] = 1\n",
    "lambda_vec2[102] = 0\n",
    "    \n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(x_train, y_train)\n",
    "y_pred2 = logic2.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, len(y_pred2)):\n",
    "    if (y_test[i] == y_pred2[i]):\n",
    "        count += 1\n",
    "\n",
    "print(\"learned w = \")        \n",
    "print(logic2.w_new)\n",
    "print(\"accuracy = \", count / len(y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Case 3: 所有實數特徵$\\lambda$都設為1, 截距項設為0, 其他則設為0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned w = \n",
      "[[ 2.54757306e-02]\n",
      " [ 2.68338059e-01]\n",
      " [-2.20821080e-01]\n",
      " [ 4.43128006e-01]\n",
      " [ 7.66990116e-01]\n",
      " [ 7.62915468e-02]\n",
      " [-4.63422171e-02]\n",
      " [-1.28758443e+00]\n",
      " [ 7.51944312e-07]\n",
      " [-1.12963414e-01]\n",
      " [ 5.48283060e-02]\n",
      " [-2.26138746e-03]\n",
      " [ 3.76517833e-02]\n",
      " [ 1.86338344e-01]\n",
      " [-4.19612079e-01]\n",
      " [-1.04346489e-01]\n",
      " [ 2.93070077e-01]\n",
      " [ 2.92224729e-01]\n",
      " [ 2.18816240e-02]\n",
      " [-7.30516160e-02]\n",
      " [ 9.74981438e-01]\n",
      " [ 2.18992474e-01]\n",
      " [-3.78240639e-02]\n",
      " [ 7.54034099e-01]\n",
      " [-2.08394382e+00]\n",
      " [ 3.19092342e-01]\n",
      " [ 1.39641685e+00]\n",
      " [-5.72016449e-01]\n",
      " [-1.05936560e+00]\n",
      " [-6.55642137e-01]\n",
      " [-3.88036577e-01]\n",
      " [-5.47067011e-01]\n",
      " [ 1.82571092e+00]\n",
      " [ 8.95057944e-01]\n",
      " [ 3.00253515e-01]\n",
      " [-5.82347589e-01]\n",
      " [ 5.28329990e-01]\n",
      " [ 1.03825743e+00]\n",
      " [ 7.51037215e-01]\n",
      " [-4.53424433e-01]\n",
      " [-2.69071876e-02]\n",
      " [ 2.36234437e-01]\n",
      " [-7.52669826e-01]\n",
      " [ 1.45241823e-01]\n",
      " [-2.00233623e+00]\n",
      " [ 8.27361950e-01]\n",
      " [ 1.25497097e+00]\n",
      " [-9.22764465e-01]\n",
      " [-8.34438329e-02]\n",
      " [ 2.32699099e-01]\n",
      " [-5.92702349e-01]\n",
      " [ 1.11240579e-01]\n",
      " [ 1.93099799e-01]\n",
      " [ 4.13058381e-01]\n",
      " [-3.83664192e-01]\n",
      " [-2.63868162e-01]\n",
      " [ 4.13741738e-02]\n",
      " [ 4.29102318e-01]\n",
      " [-4.29102318e-01]\n",
      " [ 3.17319913e-04]\n",
      " [ 6.40115459e-04]\n",
      " [ 2.95135990e-02]\n",
      " [ 4.28358923e-01]\n",
      " [ 1.18913496e+00]\n",
      " [ 5.24213675e-01]\n",
      " [-5.01169774e-02]\n",
      " [ 5.50823608e-01]\n",
      " [ 6.74417681e-01]\n",
      " [-9.62423327e-01]\n",
      " [-2.47188687e-01]\n",
      " [ 4.22778119e-01]\n",
      " [-6.38233984e-01]\n",
      " [-9.59642147e-01]\n",
      " [-4.76703527e-01]\n",
      " [ 5.82266265e-01]\n",
      " [ 2.38206931e-01]\n",
      " [-2.36216831e-01]\n",
      " [ 5.13214009e-01]\n",
      " [ 1.00609330e+00]\n",
      " [ 2.19832865e-01]\n",
      " [ 2.33159551e-01]\n",
      " [-8.46069991e-01]\n",
      " [-2.90744305e-01]\n",
      " [ 2.27002285e-01]\n",
      " [ 6.41987678e-01]\n",
      " [ 7.29262556e-01]\n",
      " [-1.06198153e+00]\n",
      " [-3.53092076e-01]\n",
      " [-9.41602947e-03]\n",
      " [ 1.67395337e-02]\n",
      " [ 1.74243000e-01]\n",
      " [-1.45906500e+00]\n",
      " [ 1.00364760e-01]\n",
      " [-9.70381891e-03]\n",
      " [-3.80716117e-01]\n",
      " [-1.79082779e-02]\n",
      " [-3.27257717e-01]\n",
      " [ 7.51083220e-01]\n",
      " [-3.18451359e-01]\n",
      " [-1.39435387e-01]\n",
      " [-4.49692076e-01]\n",
      " [ 3.80746788e-02]\n",
      " [-9.31135040e+00]]\n",
      "accuracy =  0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "lambda_vec3 = np.zeros(103)\n",
    "\n",
    "for i in range(0, 103):\n",
    "    lambda_vec3[i] = 0.5\n",
    "lambda_vec3[102] = 0\n",
    "for i in con_list:\n",
    "    lambda_vec3[i] = 1\n",
    "    \n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(x_train, y_train)\n",
    "y_pred3 = logic3.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, len(y_pred3)):\n",
    "    if (y_test[i] == y_pred3[i]):\n",
    "        count += 1\n",
    "        \n",
    "print(\"learned w = \")        \n",
    "print(logic3.w_new)\n",
    "print(\"accuracy = \", count / len(y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1.4\n",
    "    1. 將資料分成subtraining與tuning, 設置grid, a1與a2分別代表要調整的對應實數特徵、二元特徵的超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = x_train[0:27146]\n",
    "x_tun = x_train[27146:]\n",
    "y_sub = y_train[0:27146]\n",
    "y_tun = y_train[27146:]\n",
    "\n",
    "grid = [0.01, 0.02, 0.05, 1, 2, 5, 10, 20, 50, 100, 200]\n",
    "\n",
    "a1 = 0 #con\n",
    "a2 = 0 #bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使a1 = a2調整超參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "optimal = tuple()\n",
    "for i in grid:\n",
    "    a1 = i\n",
    "    a2 = i\n",
    "    \n",
    "    lambda_vec4 = np.zeros(103)\n",
    "    for j in range(0, 103):\n",
    "        lambda_vec4[j] = a2\n",
    "    lambda_vec4[102] = 0\n",
    "    for j in con_list:\n",
    "        lambda_vec4[j] = a1\n",
    "        \n",
    "    logic4 = mylogistic_l2(reg_vec = lambda_vec4, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic4.fit(x_sub, y_sub)\n",
    "    y_pred4 = logic4.predict(x_tun)\n",
    "\n",
    "    count = 0\n",
    "    for j in range(0, len(y_pred4)):\n",
    "        if (y_tun[j] == y_pred4[j]):\n",
    "            count += 1\n",
    "    if count > best:\n",
    "        optimal = (a1, a2)\n",
    "        best = count\n",
    "print(optimal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 固定a1為上一題的結果, 調整a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "a1 = optimal[0]\n",
    "optimal1 = tuple()\n",
    "for i in grid:\n",
    "    a2 = i\n",
    "    \n",
    "    lambda_vec5 = np.zeros(103)\n",
    "    for j in range(0, 103):\n",
    "        lambda_vec5[j] = a2\n",
    "    lambda_vec5[102] = 0\n",
    "    for j in con_list:\n",
    "        lambda_vec5[j] = a1\n",
    "        \n",
    "    logic5 = mylogistic_l2(reg_vec = lambda_vec5, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic5.fit(x_sub, y_sub)\n",
    "    y_pred5 = logic5.predict(x_tun)\n",
    "\n",
    "    count = 0\n",
    "    for j in range(0, len(y_pred5)):\n",
    "        if (y_tun[j] == y_pred5[j]):\n",
    "            count += 1\n",
    "    if count > best:\n",
    "        optimal1 = (a1, a2)\n",
    "        best = count\n",
    "print(optimal1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 固定a2為2.的結果, 調整a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "a2 = optimal[1]\n",
    "optimal2 = tuple()\n",
    "for i in grid:\n",
    "    a1 = i\n",
    "    \n",
    "    lambda_vec6 = np.zeros(103)\n",
    "    for j in range(0, 103):\n",
    "        lambda_vec6[j] = a2\n",
    "    lambda_vec6[102] = 0\n",
    "    for j in con_list:\n",
    "        lambda_vec6[j] = a1\n",
    "        \n",
    "    logic6 = mylogistic_l2(reg_vec = lambda_vec6, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic6.fit(x_sub, y_sub)\n",
    "    y_pred6 = logic6.predict(x_tun)\n",
    "\n",
    "    count = 0\n",
    "    for j in range(0, len(y_pred6)):\n",
    "        if (y_tun[j] == y_pred6[j]):\n",
    "            count += 1\n",
    "    if count > best:\n",
    "        optimal2 = (a1, a2)\n",
    "        best = count\n",
    "print(optimal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 選擇出最佳的(a1, a2)為(200, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 以選擇出的(a1, a2)訓練模型, 並輸出準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8445551128818061\n"
     ]
    }
   ],
   "source": [
    "lambda_vec7 = np.zeros(103)\n",
    "\n",
    "for i in range(0, 103):\n",
    "    lambda_vec7[i] = 200\n",
    "lambda_vec7[102] = 0\n",
    "for i in con_list:\n",
    "    lambda_vec7[i] = 2\n",
    "    \n",
    "logic7 = mylogistic_l2(reg_vec = lambda_vec7, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic7.fit(x_train, y_train)\n",
    "y_pred7 = logic7.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, len(y_pred7)):\n",
    "    if (y_test[i] == y_pred7[i]):\n",
    "        count += 1\n",
    "              \n",
    "print(\"accuracy = \", count / len(y_pred7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1.5\n",
    "    - 用sklearn訓練模型, 並比較與自己寫的模型訓練結果的差異\n",
    "        - 首先以subtraining與tunung調整超參數, 再以超參數訓練所有x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param =  0.005\n",
      "accuracy =  0.8029216467463479\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best = 0\n",
    "best_param = 0\n",
    "for i in grid:\n",
    "    logic8 = LogisticRegression(penalty = 'l2', tol = 1e-5, C = i, solver = 'newton-cg', fit_intercept = True, max_iter = 1000)\n",
    "    logic8.fit(x_sub, y_sub)\n",
    "    pred8 = logic8.predict(x_tun)\n",
    "    \n",
    "    count = 0\n",
    "    for j in range(0, len(pred8)):\n",
    "        if (y_tun[j] == pred8[j]):\n",
    "            count += 1\n",
    "    if count > best:\n",
    "        best_param = i\n",
    "        best = count\n",
    "\n",
    "logic9 = LogisticRegression(penalty='l2', tol=1e-5, C = best_param, solver = 'newton-cg',fit_intercept = True, max_iter = 1000)\n",
    "logic9.fit(x_train, y_train)\n",
    "pred9 = logic9.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, len(pred9)):\n",
    "    if (y_test[i] == pred9[i]):\n",
    "        count += 1\n",
    "\n",
    "print(\"best param = \", 1/best_param)\n",
    "print(\"accuracy = \", count / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 結論\n",
    "    - 自己寫的Regressor和sklearn的都有80%以上的準確度\n",
    "    - 自己寫的Regressor對於實數的特徵$\\lambda$高(200)時預測表現較好，二元特徵的$\\lambda$則是2最好\n",
    "    - sklearn則不太要求regularization的係數要很高。跑出來的準確度略低於自己寫的Regressor, 猜測可能跟自訂的grid和subtraining/tuning set有關"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
